% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit_best_learner.R
\name{fit_best_learner}
\alias{fit_best_learner}
\title{Find the best learner in terms of RMSE among specified learners using cross validation}
\usage{
fit_best_learner(
  data,
  formula,
  cv_folds = 5,
  learners = default_learners(),
  verbose = options::opt("verbose")
)
}
\arguments{
\item{data}{an optional data frame, list or environment (or object coercible
by as.data.frame to a data frame) containing the variables in the model. If
not found in data, the variables are taken from environment(formula), typically
the environment from which the function is called.}

\item{formula}{an object of class "formula" (or one that can be coerced to that class):
a symbolic description of the model to be fitted. The details of model specification are
given under ‘Details’ in the \link{glm} documentation.}

\item{cv_folds}{a \code{numeric} with the number of cross-validation folds used when fitting and
evaluating models}

\item{learners}{a \code{list} (preferably named) containing named lists of elements
\code{model} and optionally \code{grid}. The \code{model} element should be a \code{parsnip}
model specification, which is passed to \link[workflowsets:workflow_set]{workflowsets::workflow_set} as the
\code{model} argument, while the \code{grid} element is passed as the \code{grid} argument
of \link[workflowsets:option_add]{workflowsets::option_add}}

\item{verbose}{\code{numeric} verbosity level. Higher values means more information is
printed in console. A value of 0 means nothing is printed to console during
execution (Defaults to \code{2}, overwritable using option 'postcard.verbose' or environment variable 'R_POSTCARD_VERBOSE')}
}
\value{
a trained \code{workflow}
}
\description{
Find the best learner in terms of RMSE among specified learners using cross validation
}
\details{
Ensure data compatibility with the learners.
}
\examples{
# Generate some synthetic 2-armed RCT data along with historical controls
n <- 100
dat_rct <- glm_data(
  Y ~ 1+2*x1+3*a,
  x1 = rnorm(n, 2),
  a = rbinom (n, 1, .5),
  family = gaussian()
)
dat_hist <- glm_data(
  Y ~ 1+2*x1,
  x1 = rnorm(n, 2),
  family = gaussian()
)

# Fit a learner to the historical control data with default learners
fit <- fit_best_learner(Y ~ ., data = dat_hist)

# Use it fx. to predict the "control outcome" in the 2-armed RCT
predict(fit, new_data = dat_rct)
}
