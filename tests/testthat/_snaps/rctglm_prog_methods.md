# `rctglm_with_prognosticscore` returns object of correct class

    Code
      prog(ate)
    Output
      $formula
      Y ~ .
      
      
      $model_fit
      == Workflow [trained] ==========================================================
      Preprocessor: Formula
      Model: mars()
      
      -- Preprocessor ----------------------------------------------------------------
      Y ~ .
      
      -- Model -----------------------------------------------------------------------
      Selected 3 of 12 terms, and 1 of 1 predictors
      Termination condition: Reached nk 21
      Importance: W1
      Number of terms at each degree of interaction: 1 2 (additive model)
      GCV 1.073623    RSS 94.86537    GRSq 0.2633666    RSq 0.3358951
      
      $learners
      $learners$mars
      $learners$mars$model
      MARS Model Specification (regression)
      
      Main Arguments:
        prod_degree = 3
      
      Computational engine: earth 
      
      
      
      $learners$lm
      $learners$lm$model
      Linear Regression Model Specification (regression)
      
      Computational engine: lm 
      
      
      
      
      $cv_folds
      [1] 5
      
      $data
                    Y          W1
      1    0.49320997  1.65922417
      2    2.81020807  1.74830165
      3    3.30361633 -0.85544186
      4    4.51327610  1.32179050
      5    0.42877160  0.56698208
      6   -0.03639125  0.07638380
      7    1.51111188  0.94635326
      8    1.43696662 -1.46133361
      9    1.23551013  0.62796916
      10   1.91160592  0.82025914
      11   0.05112161 -0.16903290
      12   4.18967942  0.87644901
      13   2.58668340  1.73868899
      14   2.16020293 -0.97828470
      15   1.72100587 -0.15082871
      16   2.51063027  1.76005809
      17   2.28098564  1.91290571
      18   3.97554243 -1.53005055
      19   0.93273734 -0.10001167
      20   0.07489067  0.24133098
      21   2.88412710  1.61612555
      22   2.13666420 -1.44515933
      23   1.86853076  1.95556692
      24   1.39705230  1.78667293
      25   2.92095378 -1.67024977
      26   0.91120655  0.05684714
      27   2.15347219 -0.43918613
      28   2.26359498  1.62295252
      29   0.65729804 -0.21212149
      30   3.71183000  1.34401704
      31   1.94869317  0.95038247
      32   3.36867159  1.24422057
      33   0.44757758 -0.44756687
      34   1.54606758  0.74067892
      35   2.10428277 -1.98420664
      36   2.06635049  1.33166432
      37   3.73037613 -1.97066341
      38   2.35798878 -1.16936411
      39   2.74190715  1.62640563
      40   0.70617662  0.44711457
      41   0.96579612 -0.48176304
      42   2.37921399 -0.25691366
      43   3.70028037 -1.85027587
      44   3.67112178  1.89415966
      45   0.02378805 -0.27299500
      46   4.49973442  1.83030639
      47   3.51657950  1.55101962
      48   1.76995390  0.55991508
      49   3.13069656  1.88386644
      50   0.71509305  0.47535283
      51   0.83095573 -0.66629115
      52   1.91204478 -0.61300701
      53   0.39399106 -0.40605835
      54   2.55219844  1.13877110
      55   3.74197019 -1.84425404
      56   1.22441298  0.99518154
      57   1.23829405  0.70910732
      58   2.49773536 -1.31494268
      59   1.20743579 -0.95564814
      60   0.70314575  0.05765174
      61   2.84186590  0.70242910
      62   3.37314044  1.93126879
      63   2.67606665  1.03817707
      64  -0.45731133  0.26595370
      65   2.42386029  1.39875887
      66   3.48447125 -1.24210426
      67   3.00190494 -0.91485354
      68   2.25947467  1.31263394
      69  -0.65269512  0.77281928
      70   2.35291536 -1.03782104
      71   3.02439222 -1.82804482
      72   2.53261346 -1.43808362
      73   2.51687062 -1.13445834
      74   1.55503414 -0.08240574
      75   2.00706408 -1.21035863
      76   3.46362014  0.87742335
      77   2.85334522 -1.96846105
      78   0.47388675 -0.49804014
      79   2.46797386  0.05763083
      80   3.57229962 -1.99371778
      81   2.30504949  0.32641601
      82   0.80674585 -1.36837917
      83   1.23240656 -0.56388678
      84   2.46071835  0.58252751
      85   2.38276664  1.10329345
      86   1.72578145  0.25458737
      87   4.77191239 -1.06518641
      88   1.67802116 -1.64007793
      89   0.38115855 -1.65755174
      90   2.32768255 -0.77912652
      91   1.24353650  0.66970606
      92   2.81058307 -1.99904441
      93   1.56622386 -1.16572017
      94   4.69257480  1.73213651
      95   2.36328786  1.70257899
      96   1.73078868  0.93637720
      97   1.76252506 -0.66771207
      98   1.95288869  0.06025332
      99   2.33964920  0.97589859
      100  0.06257362  0.47663696
      

